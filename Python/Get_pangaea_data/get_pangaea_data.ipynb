{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PANGAEA CWS Banner](https://github.com/pangaea-data-publisher/community-workshop-material/raw/master/banner.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **How to retrieve data from PANGAEA**\n",
    "\n",
    "Version: 0.1.0<br>\n",
    "By: Michael Oellermann, Kathrin Riemann-Campe<br>\n",
    "Last updated: 2023-05-12\n",
    "\n",
    "This notebook will guide you how to retrieve diverse earth- and environmental data and its metadata from the [PANGAEA data repository](https://www.pangaea.de) using Python. It uses the [PangaeaPy package](https://github.com/pangaea-data-publisher/pangaeapy), to facilitate the data download.\n",
    "\n",
    "Run this notebook in:\n",
    "* [GoogleColab](https://colab.requery.google.com/github/pangaea-data-publisher/community-workshop-material/blob/master/Python/Get_pangaea_data/get_pangaea_data.ipynb): <a target=\"_blank\" href=\"https://colab.requery.google.com/github/pangaea-data-publisher/community-workshop-material/blob/master/Python/Get_pangaea_data/get_pangaea_data.ipynb\">\n",
    "  <img src=\"https://colab.requery.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Pangaeapy\n",
    "!pip install pangaeapy # Uncomment to install pangaeapy\n",
    "import pangaeapy as pan\n",
    "from pangaeapy.pandataset import PanDataSet\n",
    "\n",
    "# Web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "import json\n",
    "import requests\n",
    "from pandas import json_normalize\n",
    "\n",
    "# To access genebank records\n",
    "!pip install biopython # To install biopython library\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.email = \"your_email@example.com\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Query for data in PANGAEA\n",
    "\n",
    "AIM: What data can I find for a particular topic such as a species, location or author?\n",
    "\n",
    "This mirrors the query via the [PANGAEA website](https://pangaea.de/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Simple query\n",
    "Note:\n",
    "* limit = the total number of datasets to be returned from query is 500.\n",
    "    * To download > 500 use the offset attribute e.g. pan.PanQuery(\"Triticum\", limit = 500, offset=500)\n",
    "* type: \n",
    "    * parent = data collection\n",
    "    * child = data set as part of a data collection \n",
    "* score: Indicates how well the dataset matched the query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query database for Helgoland Roads\n",
    "query = pan.PanQuery(\"Triticum\")\n",
    "print(f'There have been {query.totalcount} query results')\n",
    "# Save query as dataframe\n",
    "query_results = pd.DataFrame(query.result)\n",
    "query_results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 More complex queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[More information](https://wiki.pangaea.de/wiki/PANGAEA_search) how to query with keywords\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple query terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds datasets that contain both \"marine\" and \"geology\"\n",
    "query = pan.PanQuery(\"marine geology\")\n",
    "print(f'There have been {query.totalcount} query results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional query terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find datasets that contain \"Globigerina\" and either \"falconensis\" or \"bulloides\" \n",
    "query = pan.PanQuery(\"Globigerina AND (falconensis OR bulloides)\")\n",
    "print(f'There have been {query.totalcount} query results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertain spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds datasets with uncertain spelling of single letter\n",
    "query = pan.PanQuery(\"Gl?bigerina\")\n",
    "print(f'There have been {query.totalcount} query results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds datasets with \"Neogloboquadrina\" regardless of your spelling mistake\n",
    "query = pan.PanQuery(\"~Neogloboqadrina\")\n",
    "print(f'There have been {query.totalcount} query results') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \tFinds datasets of author \"Herzschuh\"\n",
    "query = pan.PanQuery(\"citation:author:Herzschuh\")\n",
    "print(f'There have been {query.totalcount} query results') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query database for \"Deep-sea Sponge Microbiome Project\" within a certain geolocation\n",
    "query = pan.PanQuery(\"Globigerina bulloides\", limit = 500, bbox=(17.7, 67.7, 21, 69))\n",
    "print(f'There have been {query.totalcount} query results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Queries exceeding 500 results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to query Pangaea without limited results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query pangaea for datasets\n",
    "# This function overcomes the limit of 500 datasets\n",
    "def query_pangaea(query_term = \"\", limit = 500, exclude_collection = True):\n",
    "    query = pan.PanQuery(query_term, limit = limit)\n",
    "    print(f'{query.totalcount} total query results. Query limited to {limit} results.')\n",
    "\n",
    "    # Save query as dataframe\n",
    "    query_results = pd.DataFrame(query.result)\n",
    "    \n",
    "    # Constrain query to limit\n",
    "    if limit:\n",
    "        query.totalcount = limit\n",
    "\n",
    "    # if more than 500 query increase the offset to overcome data download limit\n",
    "    if query.totalcount > 500:\n",
    "        for offset in range(500, int(query.totalcount), 500):\n",
    "            # new query with increased offset\n",
    "            query = pan.PanQuery(query_term, offset=offset, limit = 500)\n",
    "            # Attach further query results\n",
    "            query_results = pd.concat([query_results, pd.DataFrame(query.result)])\n",
    "\n",
    "    # Exclude data collection (parents) if true\n",
    "    if exclude_collection:        \n",
    "        query_results = query_results[query_results.type == \"child\"]\n",
    "        print(f'{len(query_results)} child datasets extracted')\n",
    "\n",
    "    # Delete redundant columns\n",
    "    query_results = query_results.drop([\"html\", \"position\"], axis = 1)\n",
    "\n",
    "    # Add query term to table\n",
    "    query_results[\"query_term\"] = query_term\n",
    "    \n",
    "    return query_results.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PANGAEA query\n",
    "query_term = \"citation:author:Herzschuh\"\n",
    "query_results = query_pangaea(query_term, limit = 50, exclude_collection=True)\n",
    "query_results.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Pangaea ID (optional for labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract and add pangaea ID to query result dataframe\n",
    "def add_pangaea_id(query_df):\n",
    "    # Extract PANGAEA dataset ID\n",
    "    if \"pangaea_id\" not in query_df.columns:\n",
    "        return query_df.insert(0, \"pangaea_id\", [int(id.split(\".\")[-1:][0]) for id in query_df.URI])\n",
    "\n",
    "# Add pangaea dataset ids\n",
    "add_pangaea_id(query_results)\n",
    "query_results.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Quiz\n",
    "\n",
    "[More information](https://wiki.pangaea.de/wiki/PANGAEA_search) how to query with keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 How many datasets contain \"Octopus vulgaris\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 How many datasets contain \"Gadus morhua\" in the title only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 How many datasets did the author Hannes Grobe publish?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 How many datasets measured \"Temperature, water\" using a CTD/Rosette?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Download single dataset\n",
    "\n",
    "AIM: How can I download a single dataset right into Python or to my harddrive?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PANGAEA query\n",
    "query_term = \"Deep-sea Sponge Microbiome Project\"\n",
    "query_results = query_pangaea(query_term, limit = 50, exclude_collection=True)\n",
    "# Add pangaea dataset ids\n",
    "add_pangaea_id(query_results)\n",
    "query_results.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset from PANGAEA\n",
    "Dataset: https://doi.pangaea.de/10.1594/PANGAEA.923033"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the full url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PanDataSet(\"https://doi.pangaea.de/10.1594/PANGAEA.923033\")\n",
    "print(ds.data.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PanDataSet(\"doi:10.1594/PANGAEA.923033\")\n",
    "print(ds.data.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the PANGAEA ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PanDataSet(923033)\n",
    "print(ds.data.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate to long parameter names\n",
    "Because by default parameters are abbreviated without units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate short parameters names to long names including unit\n",
    "def get_long_parameters(ds):\n",
    "    \"\"\"Translate short parameters names to long names including unit\n",
    "\n",
    "    Args:\n",
    "        ds (PANGAEA dataset): PANGAEA dataset\n",
    "    \"\"\"\n",
    "    ds.data.columns =  [f'{param.name} [{param.unit}]' if param.unit else param.name for param in ds.params.values()]\n",
    "\n",
    "print(ds.data.columns[:10])\n",
    "get_long_parameters(ds)\n",
    "ds.data.columns[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display location of dataset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sampling points on interactive plotly map\n",
    "fig = px.scatter_mapbox(ds.data, lat=\"LATITUDE\", lon=\"LONGITUDE\", \n",
    "                        hover_name=\"Event label\", \n",
    "                        hover_data=['LATITUDE', 'LONGITUDE', 'DEPTH, water [m]', 'Species', 'Gear'], \n",
    "                        zoom=0, height=300)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data folder\n",
    "data_folder = \"pangaea_data\"\n",
    "# Check if it already exists before creating it\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "# Save to csv\n",
    "print(f'PANGAEA dataset {ds.id} saved')\n",
    "ds.data.to_csv(os.path.join(data_folder, f'Pangaea_dataset_{ds.id}.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Download multiple datasets\n",
    "\n",
    "AIM: How can I download multiple datasets right into Python or on my harddrive?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PANGAEA query\n",
    "query_term = \"Deep-sea Sponge Microbiome Project\"\n",
    "query_results = query_pangaea(query_term, limit = 50, exclude_collection=True)\n",
    "query_results.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download multiple datasets\n",
    "Note: \n",
    "* Data collections and restricted datasets cannot be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pangaea dataset ids\n",
    "add_pangaea_id(query_results)\n",
    "\n",
    "# Create dictionary to store dataframes in\n",
    "data_dict = {}\n",
    "# Loop over IDs and download datasets\n",
    "for pangaea_id in query_results.pangaea_id[:4]:\n",
    "    print(\"\".join(40*[\"-\"]))\n",
    "    print(f'Pangaea ID: {pangaea_id}')\n",
    "    # Cache\n",
    "    ds = PanDataSet(pangaea_id, enable_cache=True)\n",
    "    # Translate to long parameter names\n",
    "    get_long_parameters(ds)\n",
    "    print(f'Dataset title: {ds.title}')\n",
    "    print(ds.data.head(2))\n",
    "    data_dict[pangaea_id] = ds.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data folder\n",
    "data_folder = \"pangaea_data\"\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "# Loop over each dataset in the dictionary and save to csv\n",
    "for key, df in data_dict.items():\n",
    "    print(f'PANGAEA dataset {key} saved')\n",
    "    # Save to csv\n",
    "    data_dict[key].to_csv(os.path.join(data_folder, f'Pangaea_dataset_{key}.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Quiz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Download this dataset and identify the first event name\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.947275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Download this dataset and identify the number of sampling points >1000m\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.943624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Was there a sampling point in Australia for this dataset?\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.943455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Get metadata for each dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from PANGAEA\n",
    "ds = PanDataSet(923033, include_data=False)\n",
    "ds.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic metadata retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "print(f'Title: {ds.title}')\n",
    "# Abstract\n",
    "print(f'Abstract: {ds.abstract}')\n",
    "# Publication date\n",
    "print(f'Publication date: {ds.date}')\n",
    "# Authors\n",
    "print(f'Authors: {\"; \".join([x.fullname for x in ds.authors])}')\n",
    "# Author orcids\n",
    "print(f'Orcids: {\"; \".join([x.ORCID if x.ORCID else \"no ORCID\" for x in ds.authors])}')\n",
    "# Citation\n",
    "print(f'Citation: {ds.citation}')\n",
    "# doi\n",
    "print(f'doi: {ds.doi}')\n",
    "# Geolocation\n",
    "print(f'Latitude: {ds.geometryextent[\"meanLatitude\"]}')\n",
    "print(f'Longitude: {ds.geometryextent[\"meanLongitude\"]}')\n",
    "# Parameters\n",
    "params = \"; \".join([f'{param.name} [{param.unit}]' if param.unit else param.name for param in ds.params.values()])\n",
    "print(f'Parameters: {params}')\n",
    "# Event devices\n",
    "print(f'Event devices: {\"; \".join(set([device for device in ds.getEventsAsFrame()[\"device\"]]))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Getting metadata for multiple datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Using Pangaeapy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract PANGAEA metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract metadata from Pangaea dataset\n",
    "def get_pangaea_meta(pangaea_id):\n",
    "    try:\n",
    "        print(f'Extract metadata for Pangaea ID: {pangaea_id}')\n",
    "        # Get metadata for pangaea dataset\n",
    "        ds = pan.PanDataSet(pangaea_id, enable_cache=True, include_data=False)\n",
    "        # Create data frame to store metadata\n",
    "        meta = pd.DataFrame({\"pangaea_id\": [pangaea_id]})\n",
    "        # Extract and add metadata    \n",
    "        meta[\"year\"] = ds.year\n",
    "        meta[\"authors\"] = \"; \".join([x.fullname for x in ds.authors])\n",
    "        meta[\"title\"] = ds.title\n",
    "        meta[\"abstract\"] = ds.abstract \n",
    "        meta[\"citation\"] = ds.citation\n",
    "        meta[\"parameters\"]= \"; \".join([f'{param.name} [{param.unit}]' if param.unit else param.name for param in ds.params.values()])\n",
    "        meta[\"publication_date\"] = ds.date\n",
    "        # Check if there are geometry metadata\n",
    "        if ds.geometryextent:\n",
    "            meta[\"mean_latitude\"] = ds.geometryextent[\"meanLatitude\"]\n",
    "            meta[\"mean_longitude\"] = ds.geometryextent[\"meanLongitude\"]\n",
    "        # Check if events are available\n",
    "        if not ds.getEventsAsFrame().empty:   \n",
    "            meta[\"events\"] = \"; \".join(ds.getEventsAsFrame()[\"label\"])\n",
    "            meta[\"event_device\"] = ds.getEventsAsFrame()[\"device\"]\n",
    "            meta[\"elevation\"] = ds.getEventsAsFrame()[\"elevation\"]\n",
    "            meta[\"campaign\"] = ds.getEventsAsFrame()[\"campaign\"]\n",
    "            meta[\"location\"] = ds.getEventsAsFrame()[\"location\"]\n",
    "        meta[\"doi\"] = ds.doi\n",
    "        meta[\"datastatus\"] = ds.datastatus\n",
    "    except AttributeError:\n",
    "        meta = pd.DataFrame()\n",
    "    \n",
    "    return meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to download metadata from multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download multiple Pangaea metadata\n",
    "def get_pangaea_meta_df(query_term, pangaea_id_list, folder = \"PANGAEA_metadata\"):\n",
    "    # Create folder for metadata\n",
    "    if os.path.isdir(folder):\n",
    "        print(f'{folder} already exists')\n",
    "    # if not create it  Â  \n",
    "    else:\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    # Create file path\n",
    "    file_path = os.path.join(os.getcwd(), \"PANGAEA_metadata\", f'metadata_{query_term.replace(\":\", \"_\")}.csv')\n",
    "    print(file_path)\n",
    "    # Add check if data have already been downloaded\n",
    "    if os.path.isfile(file_path):\n",
    "        print(\"File already exists\")\n",
    "        meta_df = pd.read_csv(file_path)\n",
    "    else:\n",
    "        meta_df = {}\n",
    "        # Retrieve and store metadata in dictionary\n",
    "        for id in pangaea_id_list:\n",
    "            meta_df[id] = get_pangaea_meta(id)\n",
    "        # Join all metadata into single dataframe\n",
    "        meta_df = pd.concat(meta_df).reset_index(drop=True)\n",
    "        # Save metadata to csv file\n",
    "        meta_df.to_csv(file_path, index=False)\n",
    "        print(f'Pangaea metadata saved as {file_path}')\n",
    "    return meta_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use these functions to download metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PANGAEA query\n",
    "query_term = \"citation:author:Herzschuh\"\n",
    "query_results = query_pangaea(query_term, limit = 50)\n",
    "# Add pangaea dataset ids\n",
    "add_pangaea_id(query_results)\n",
    "# Extract metadata for all query results\n",
    "meta_df = get_pangaea_meta_df(query_term = query_term, pangaea_id_list = query_results[\"pangaea_id\"])\n",
    "meta_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Alternative way to retrieve metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 HTML Scraping\n",
    "* --> To access metadata via direct web scraping\n",
    "* ... and to apply this more generic approach to scrape data from other repositories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First define scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the full PANGAEA dataset web content\n",
    "def get_html(url):\n",
    "    \"\"\"Function to extract html web content\n",
    "\n",
    "    Args:\n",
    "        dataset_id (str): PANGAEA dataset ID\n",
    "\n",
    "    Returns:\n",
    "        str: html content of PANGAEA dataset\n",
    "    \"\"\"\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Function to extract PANGAEA metadata\n",
    "def get_pan_metadata(dataset_html, metadata):\n",
    "    \"\"\"Function to scrape metadata from PANGAEA dataset html content\n",
    "\n",
    "    Args:\n",
    "        dataset_html (str): html content of PANGAEA dataset\n",
    "        metadata (str): metadata type to be extracted\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted metadata\n",
    "    \"\"\"\n",
    "    return dataset_html.find(\"meta\", attrs={\"name\": metadata}).get(\"content\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See what metadata are available\n",
    "Note:\n",
    "* Example dataset: https://doi.org/10.1594/PANGAEA.923035\n",
    "* You can view the source code in the browser by pressing CTRL + U (in Firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape PANGAEA dataset\n",
    "html = get_html(\"https://doi.org/10.1594/PANGAEA.923035\")\n",
    "# Extract all available metadata types\n",
    "for meta in html.find_all(\"meta\"):\n",
    "    if meta.has_attr(\"name\"):\n",
    "        print(meta.attrs[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the abstract\n",
    "html.find(\"meta\", attrs={\"name\": \"title\"}).get(\"content\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape the html content for multiple PANGAEA dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PANGAEA query\n",
    "query_term = \"Deep-sea Sponge Microbiome Project\"\n",
    "query_results = query_pangaea(query_term, limit = 5, exclude_collection=True)\n",
    "query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate url from uri\n",
    "query_results[\"url\"] = [f'https://doi.org/{uri.split(\":\")[-1:][0]}' for uri in query_results.URI]\n",
    "# Scrape the html content for each PANGAEA dataset\n",
    "query_results[\"html\"] = [get_html(url) for url in query_results[\"url\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exctract desired metadata from each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract desired metadata from dataset html\n",
    "for counter, metadata in enumerate([\"title\", \"author\", \"date\", \"geo.position\", \"description\"]):\n",
    "    # Check if metadata already exist\n",
    "    if metadata not in query_results.columns:\n",
    "        query_results.insert(counter+1, metadata, [get_pan_metadata(html, metadata) for html in query_results[\"html\"]])\n",
    "\n",
    "# Extract the abstract\n",
    "query_results[\"abstract\"] = [html.find(\"div\", attrs={\"class\": \"abstract\"}).get_text() for html in query_results[\"html\"]]\n",
    "query_results.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "query_results.to_csv(os.path.join(\"PANGAEA_metadata\", 'Pangaea_metadata_html.csv'), index=False)\n",
    "query_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Metadata from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract json string from html\n",
    "query_results[\"json\"] = [html.find(\"script\", attrs={\"type\": \"application/ld+json\"}).string for html in query_results[\"html\"]]\n",
    "# Alternative way of doing the same thing (it is 5 times slower though)\n",
    "#query_results[\"json\"] = [requests.get(url, headers={'Accept': 'application/ld+json'}).json() for url in query_results[\"url\"]]\n",
    "\n",
    "#See what metadata are available\n",
    "print(json.loads(query_results[\"json\"][0]))\n",
    "# Ad json metadata to dataframe\n",
    "print([json.loads(json_str)[\"name\"] for json_str in query_results[\"json\"]])\n",
    "# Extract nested metadata such as ORCID ID\n",
    "print(json_normalize(json.loads(query_results[\"json\"][0])[\"creator\"])[\"@id\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Quiz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 What is the title of this dataset?\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.937210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 What is the publication date of this dataset?\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.863967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Did they measure temperature in this dataset?\n",
    "https://doi.pangaea.de/10.1594/PANGAEA.863975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Download specific parameters across multiple datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Check the frequency of parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data headers from all data frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame()\n",
    "# Extract and combine headers of all data sets\n",
    "for key, df in data_dict.items():\n",
    "    params = pd.concat([params, df.columns.to_frame()], ignore_index=True, axis=0)\n",
    "# Rename the parameter column\n",
    "params = params.rename(columns={0: \"parameters\"})\n",
    "# Show the first 10 parameters\n",
    "params.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot parameter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the parameter frequency\n",
    "param_count = params[\"parameters\"].value_counts()\n",
    "print(param_count.head(10))\n",
    "# Plot the parameter frequency\n",
    "plt.figure(figsize=(10,3))\n",
    "count_plot = sns.barplot(x = param_count.index[:15], y = param_count.values[:15], color=\"darkcyan\")\n",
    "count_plot = count_plot.set_xticklabels(count_plot.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Extract and combine parameters from data frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract specific parameter(s) from dataframes\n",
    "**This is a key benefit of harmonised parameters in a well curated data repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and extract desired parameters across all dataframes\n",
    "def get_param_data(data_dict, params):\n",
    "    \"\"\"Function to find and extract desired parameters across all dataframes\n",
    "\n",
    "    Args:\n",
    "        params (list): List of parameters to be extracted\n",
    "\n",
    "    Returns:\n",
    "        pandas.core.frame.DataFrame: Data frame containing data for all parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Define empty dictionary to temporarily store extracted data\n",
    "    extracted_data = {}\n",
    "    # Loop over all dataframe, look for and extract parameters\n",
    "    for key, df in data_dict.items():\n",
    "        # Convert headers to lowercase to improve matching\n",
    "        df.columns = [x.lower() for x in df.columns]\n",
    "        # Find parameters that exists in the dataset\n",
    "        found_params = list(set([x.lower() for x in params]).intersection(set(df.columns)))\n",
    "        if found_params:\n",
    "            print(f'Found the parameters {found_params} in dataset {key}')\n",
    "            # Copy found parameters to new dataframe\n",
    "            df_sub = df[found_params]\n",
    "            # Insert PANGAEA dataset ID\n",
    "            df_sub.insert(0, \"Pangaea_dataset_id\", key)\n",
    "            # Store extracted data in dictionary\n",
    "            extracted_data[key] = df_sub\n",
    "\n",
    "    # Join all dataframe in dictionary\n",
    "    extracted_data = pd.concat(extracted_data, ignore_index = True)\n",
    "    return extracted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and save specific parameters from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter all parameters to be extracted\n",
    "extracted_data = get_param_data(data_dict, [\"LATITUDE\", \"LONGITUDE\", 'DATE/TIME', \"DEPTH, water [m]\", \"Salinity\"])\n",
    "# Save extracted data parameters\n",
    "extracted_data.to_csv(os.path.join(data_folder, 'Extracted_data.csv'), index=False)\n",
    "extracted_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Download linked genetic data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Download PANGAEA dataset with genetic accession numbers\n",
    "Dataset: https://doi.pangaea.de/10.1594/PANGAEA.937551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from PANGAEA\n",
    "ds = PanDataSet(937551)\n",
    "get_long_parameters(ds)\n",
    "df = ds.data.head(4)\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Download Genebank records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract NCBI accession number from dataset\n",
    "df.loc[:,\"Accession number, genetics\"] = [x.split(\":\")[1] for x in df.loc[:,\"Accession number, genetics\"]]\n",
    "# Fetch gene records from NCBI\n",
    "records = []\n",
    "for acc_id in df[\"Accession number, genetics\"]:\n",
    "    print(acc_id)\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", rettype=\"fasta\", retmode=\"text\",\n",
    "                          id=acc_id)\n",
    "    records.append(SeqIO.read(handle, 'fasta'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Add genetic records to PANGAEA data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gene description\n",
    "df.loc[:, \"Gene\"] = [record.description for record in records]\n",
    "# Add genetic sequence\n",
    "df.loc[:, \"Sequence\"] = [record.seq for record in records]\n",
    "# Save to file\n",
    "df.to_csv(os.path.join(data_folder, 'PANGAEA_NCBI_data.csv'), index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Download binary files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Download PANGAEA dataset with image data\n",
    "Dataset: https://doi.pangaea.de/10.1594/PANGAEA.943250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from PANGAEA\n",
    "pan_id = 943250\n",
    "ds = PanDataSet(pan_id)\n",
    "# Spell out abbreviated parameters\n",
    "get_long_parameters(ds)\n",
    "df = ds.data.iloc[22:25,:]\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file urls\n",
    "df[\"image_url\"] = [f'https://download.pangaea.de/dataset/{pan_id}/files/{img}' for img in df['Image']]\n",
    "# Download images\n",
    "for i, file_url in enumerate(df[\"image_url\"]):\n",
    "    urlretrieve(file_url, os.path.join(data_folder, df[\"Image\"].iloc[i]))\n",
    "    print(f'{file_url} downloaded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
